{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference notebook\n",
    "Largely based on https://www.kaggle.com/chrisstan/darknet2pytorch-apache-license-yolov4-inference\n",
    "Hoping to add elements from https://www.kaggle.com/shonenkov/bayesian-optimization-wbf-efficientdet \n",
    "Also using PL from https://www.kaggle.com/hawkey/yolov5-pseudo-labeling-oof-evaluation\n",
    "\n",
    "When changing settings, make sure to change all resolutions (both 1024 and 1023). Also make sure the thresholds are all changed to the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/pytorchyolov4/tool .\n",
    "#!cp ../input/yolov4weights/submit.weights ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../input/weightedboxesfusion/\")\n",
    "\n",
    "\n",
    "from ensemble_boxes import *\n",
    "import glob\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.plots import plot_objective, plot_evaluations, plot_convergence, plot_regret\n",
    "from skopt.space import Categorical, Integer, Real\n",
    "from tool.utils import *\n",
    "from tool.torch_utils import *\n",
    "from tool.darknet2pytorch import Darknet\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "cfgfile = '../input/yolov4weights/submit.cfg'\n",
    "weightfile = '../input/yolov4weights/submit.weights' \n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "m = Darknet(cfgfile)\n",
    "m.load_weights(weightfile)\n",
    "if use_cuda:\n",
    "    m.cuda()\n",
    "num_classes = m.num_classes\n",
    "class_names = load_class_names('../input/yolov4weights/wheat.names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "            A.Resize(height=704, width=704, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT_PATH = '../input/global-wheat-detection/test'\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "\n",
    "    def __init__(self, image_ids, transforms=None):\n",
    "        super().__init__()\n",
    "        self.image_ids = image_ids\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "        image = cv2.imread(f'{DATA_ROOT_PATH}/{image_id}.jpg')\n",
    "        image = cv2.resize(image, (704, 704))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms:\n",
    "            sample = {'image': image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "        return image, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "    \n",
    "dataset = DatasetRetriever(\n",
    "    image_ids=np.array([path.split('/')[-1][:-4] for path in glob(f'{DATA_ROOT_PATH}/*.jpg')]),\n",
    "    transforms=get_valid_transforms()\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseWheatTTA:\n",
    "    \"\"\" author: @shonenkov \"\"\"\n",
    "    image_size = 704\n",
    "\n",
    "    def augment(self, image):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def batch_augment(self, images):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def deaugment_boxes(self, boxes):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class TTAHorizontalFlip(BaseWheatTTA):\n",
    "    \"\"\" author: @shonenkov \"\"\"\n",
    "\n",
    "    def augment(self, image):\n",
    "        return image.flip(1)\n",
    "    \n",
    "    def batch_augment(self, images):\n",
    "        return images.flip(2)\n",
    "    \n",
    "    def deaugment_boxes(self, boxes):\n",
    "        boxes[:, [1,3]] = self.image_size - boxes[:, [3,1]]\n",
    "        return boxes\n",
    "\n",
    "class TTAVerticalFlip(BaseWheatTTA):\n",
    "    \"\"\" author: @shonenkov \"\"\"\n",
    "    \n",
    "    def augment(self, image):\n",
    "        return image.flip(2)\n",
    "    \n",
    "    def batch_augment(self, images):\n",
    "        return images.flip(3)\n",
    "    \n",
    "    def deaugment_boxes(self, boxes):\n",
    "        boxes[:, [0,2]] = self.image_size - boxes[:, [2,0]]\n",
    "        return boxes\n",
    "    \n",
    "class TTARotate90(BaseWheatTTA):\n",
    "    \"\"\" author: @shonenkov \"\"\"\n",
    "    \n",
    "    def augment(self, image):\n",
    "        return torch.rot90(image, 1, (1, 2))\n",
    "\n",
    "    def batch_augment(self, images):\n",
    "        return torch.rot90(images, 1, (2, 3))\n",
    "    \n",
    "    def deaugment_boxes(self, boxes):\n",
    "        res_boxes = boxes.copy()\n",
    "        res_boxes[:, [0,2]] = self.image_size - boxes[:, [1,3]]\n",
    "        res_boxes[:, [1,3]] = boxes[:, [2,0]]\n",
    "        return res_boxes\n",
    "\n",
    "class TTARotate180(BaseWheatTTA):\n",
    "    \n",
    "    def augment(self, image):\n",
    "        tmp = torch.rot90(image, 1, (1, 2))\n",
    "        return torch.rot90(tmp, 1, (1, 2))\n",
    "\n",
    "    def batch_augment(self, images):\n",
    "        tmp = torch.rot90(images, 1, (2, 3))\n",
    "        return torch.rot90(tmp, 1, (2, 3))\n",
    "    \n",
    "    def deaugment_boxes(self, boxes):\n",
    "        tmp = TTARotate90().deaugment_boxes(boxes)\n",
    "        return TTARotate90().deaugment_boxes(tmp)\n",
    "    \n",
    "class TTARotate270(BaseWheatTTA):\n",
    "    \n",
    "    def augment(self, image):\n",
    "        tmp = TTARotate180().augment(image)\n",
    "        return torch.rot90(tmp, 1, (1, 2))\n",
    "\n",
    "    def batch_augment(self, images):\n",
    "        tmp = TTARotate180().batch_augment(images)\n",
    "        return torch.rot90(tmp, 1, (2, 3))\n",
    "    \n",
    "    def deaugment_boxes(self, boxes):\n",
    "        tmp = TTARotate180().deaugment_boxes(boxes)\n",
    "        return TTARotate90().deaugment_boxes(tmp)\n",
    "    \n",
    "class TTACompose(BaseWheatTTA):\n",
    "    \"\"\" author: @shonenkov \"\"\"\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def augment(self, image):\n",
    "        for transform in self.transforms:\n",
    "            image = transform.augment(image)\n",
    "        return image\n",
    "    \n",
    "    def batch_augment(self, images):\n",
    "        for transform in self.transforms:\n",
    "            images = transform.batch_augment(images)\n",
    "        return images\n",
    "    \n",
    "    def prepare_boxes(self, boxes):\n",
    "        result_boxes = boxes.copy()\n",
    "        result_boxes[:,0] = np.min(boxes[:, [0,2]], axis=1)\n",
    "        result_boxes[:,2] = np.max(boxes[:, [0,2]], axis=1)\n",
    "        result_boxes[:,1] = np.min(boxes[:, [1,3]], axis=1)\n",
    "        result_boxes[:,3] = np.max(boxes[:, [1,3]], axis=1)\n",
    "        return result_boxes\n",
    "    \n",
    "    def deaugment_boxes(self, boxes):\n",
    "        for transform in self.transforms[::-1]:\n",
    "            boxes = transform.deaugment_boxes(boxes)\n",
    "        return self.prepare_boxes(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_det(index, det, score_threshold=0.35):\n",
    "    scores = det[index][:, 5].copy()\n",
    "    det = det[index][:, :4].copy()\n",
    "    bboxes = np.zeros((det.shape))\n",
    "    bboxes[:, 0] = (det[:, 0] * 704).astype(int)\n",
    "    bboxes[:, 1] = (det[:, 1] * 704).astype(int)\n",
    "    bboxes[:, 2] = (det[:, 2] * 704).astype(int)\n",
    "    bboxes[:, 3] = (det[:, 3] * 704).astype(int)\n",
    "    bboxes = (bboxes).clip(min = 0, max = 703).astype(int)\n",
    "    \n",
    "    indexes = np.where(scores>score_threshold)\n",
    "    bboxes = bboxes[indexes]\n",
    "    scores = scores[indexes]\n",
    "    return bboxes, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = TTACompose([\n",
    "    TTARotate270(),\n",
    "    #TTAVerticalFlip(),\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "image, image_id = dataset[4] # 4 is good for fp, 3 is good for fn\n",
    "\n",
    "numpy_image = image.permute(1,2,0).cpu().numpy().copy()\n",
    "\n",
    "ax[0].imshow(numpy_image);\n",
    "ax[0].set_title('original')\n",
    "\n",
    "tta_image = transform.augment(image)\n",
    "print(tta_image.shape)\n",
    "tta_image_numpy = tta_image.permute(1,2,0).cpu().numpy().copy()\n",
    "\n",
    "det = do_detect(m, tta_image_numpy, 0.35, 0.5, use_cuda=1)\n",
    "detnp = np.array(det)\n",
    "boxes, scores = process_det(0, detnp)\n",
    "\n",
    "for box in boxes:\n",
    "    cv2.rectangle(tta_image_numpy, (box[0], box[1]), (box[2],  box[3]), (0, 1, 0), 2)\n",
    "\n",
    "print(detnp.shape)\n",
    "\n",
    "ax[1].imshow(tta_image_numpy);\n",
    "ax[1].set_title('tta')\n",
    "\n",
    "boxes = transform.deaugment_boxes(boxes)\n",
    "for box in boxes:\n",
    "    cv2.rectangle(numpy_image, (box[0], box[1]), (box[2],  box[3]), (0, 1, 0), 2)\n",
    "\n",
    "ax[2].imshow(numpy_image);\n",
    "ax[2].set_title('deaugment predictions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "tta_transforms = []\n",
    "for tta_combination in product([TTAHorizontalFlip(), None], \n",
    "                               [TTAVerticalFlip(), None],\n",
    "                               [TTARotate90(), None],\n",
    "                               [TTARotate180(), None],\n",
    "                               [TTARotate270(), None]):\n",
    "    tta_transforms.append(TTACompose([tta_transform for tta_transform in tta_combination if tta_transform]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tta_predictions(images, score_threshold=0.35):\n",
    "    with torch.no_grad():\n",
    "        images = torch.stack(images).float().cuda()\n",
    "        predictions = []\n",
    "        #print('images.shape', images.shape)\n",
    "        for tta_transform in tta_transforms:\n",
    "            result = []\n",
    "            input_img = tta_transform.batch_augment(images.clone()).permute(0,2,3,1).cpu().numpy()\n",
    "            #print('input_img',input_img.shape)\n",
    "            det = do_detect(m, input_img, 0.35, 0.5, use_cuda=1)\n",
    "            #print([len(i) for i in det])\n",
    "            det = [np.array(i)for i in det]\n",
    "            #print(det)\n",
    "            for i in range(images.shape[0]):\n",
    "                boxes, scores = process_det(i, det)\n",
    "                boxes = tta_transform.deaugment_boxes(boxes.copy())\n",
    "                result.append({\n",
    "                    'boxes': boxes,\n",
    "                    'scores': scores,\n",
    "                })\n",
    "            predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "import ensemble_boxes \n",
    "\n",
    "def run_wbf(predictions, image_index, image_size=704, iou_thr=0.34, skip_box_thr=0.31, weights=None):\n",
    "    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist() for prediction in predictions]\n",
    "    scores = [prediction[image_index]['scores'].tolist() for prediction in predictions]\n",
    "    labels = [np.ones(prediction[image_index]['scores'].shape[0]).astype(int).tolist() for prediction in predictions]\n",
    "    boxes, scores, labels = ensemble_boxes.ensemble_boxes_wbf.weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    boxes = boxes*(image_size-1)\n",
    "    return boxes, scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for j, (images, image_ids) in enumerate(data_loader):\n",
    "    break\n",
    "\n",
    "predictions = make_tta_predictions(images)\n",
    "\n",
    "i = 1\n",
    "sample = images[i].permute(1,2,0).cpu().numpy()\n",
    "boxes, scores, labels = run_wbf(predictions, image_index=i)\n",
    "boxes = boxes.round().astype(np.int32).clip(min=0, max=703)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "for box in boxes:\n",
    "    cv2.rectangle(sample, (box[0], box[1]), (box[2], box[3]), (1, 0, 0), 1)\n",
    "\n",
    "ax.set_axis_off()\n",
    "ax.imshow(sample);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prediction_string(boxes, scores):\n",
    "    pred_strings = []\n",
    "    for j in zip(scores, boxes):\n",
    "        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n",
    "    return \" \".join(pred_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for images, image_ids in data_loader:\n",
    "    try:\n",
    "        predictions = make_tta_predictions(images)\n",
    "    \n",
    "        for i, image in enumerate(images):\n",
    "            \n",
    "            boxes, scores, labels = run_wbf(predictions, image_index=i)\n",
    "            boxes = (boxes*(1024 / 704)).round().astype(np.int32).clip(min=0, max=1023)\n",
    "            image_id = image_ids[i]\n",
    "\n",
    "            boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "            boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "            if len(boxes) > 0:\n",
    "                result = {\n",
    "                    'image_id': image_id,\n",
    "                    'PredictionString': format_prediction_string(boxes, scores)\n",
    "                }\n",
    "                results.append(result)\n",
    "    except:\n",
    "        for i, image in enumerate(images):\n",
    "            image_id = image_ids[i]\n",
    "            result = {\n",
    "                'image_id': image_id,\n",
    "                'PredictionString': ''\n",
    "            }\n",
    "            results.append(result)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\n",
    "test_df.to_csv('submission.csv', index=False)\n",
    "test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}